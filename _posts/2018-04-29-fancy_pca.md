---
layout: post
title: Fancy PCA
subtitle: Imagenet Classification With Deep Convolutional Neural Networks
image: /img/toxic_emoji.jpg
tags: [Classifier, Neural Networks, CNN, Image Augmentation, Feature Engineering, Keras, Tensorflow]
---

How to implement 'Fancy PCA' image augmentation in Python from the paper "Imagenet Classification With Deep Convolutional Neural Networks"

Currently I'm working on an image classification problem that has 128 classes. (With no class overlap)

I've been using transfer learning so far, primarily Inception V3 but also VGG16 and ResNet 50. In attempting to improve my results I read the paper "Imagenet Classification With Deep Convolutional Neural Networks" by Krizhevsky, Sutskever, and Hinton. The paper has a whole section (4.1) on image augmentation, which has been something of interest to me since my entry in the Iceberg/Ship classification contest.  In that contest I only augmented by flipping images over the vertical axis.

For this furniture contest the pictures were scraped from websites and vary in resolution and aspect ratio. So before this paper I had been doing rotation and cropping augmentation. However, this paper introduced something new to me that they called "Fancy PCA".  Details on Fancy PCA will follow below but first some results forward images to demonstrate what it is doing.

Essentially what is happening is that we are finding the eigenvector and eigenvalues of an image. (Really a 2d matrix, in this case consisting of each pixel and it's RGB components) We then draw a random number (α in the formula below) for each color one time per image. Alpha (α) comes from a normal distribution and is zero centered. The paper suggests a standard deviation of 0.1 for that distribution. Then the principal components of the image are scaled by this alpha value and finally added to the pixel's color channels.  This appears to alter the contrast, and somewhat the hue, of the image in a randomized manner but in such a way that conserves the image detail.

This is as opposed to simply adding a random value to each color channel of an image. Most of the time the value changes at the recommended values do not appear noticable to the human eye. (But can be verified by subtracting the modified numpy matrix from the initial numpy matrix.)  For the purposes of this blog post the values have been increased by ~1000x to make the changes more obvious. Also, in the comparison images an image using an algorithm that simply adds random values to a color channel has also been provided. In order to allow comparison of the techniques.

<p align="center">
<img src="/img/fancy_pca/chair_pca.png" width="400" align="middle">
</p>

###### One can see that the far right images have clownish, rainbow distortions because of how much the color channels have been impacted.  The middle images, "fancy PCA", have been color shifted but the distortion is not as dire despite the large magnitude. The middle image distortion, in many pictures, looks like a temperature based (Kelvin) white balance shift in comparison. Again the distortions are about 1000x the recommended value.

<p align="center">
<img src="/img/fancy_pca/rack_pca.png" width="400" align="middle">
</p>

###### For this rack picture we can see how much the colors are distored in the 3rd column of pictures which is simply adding random values from a normal distribution to each color channel. The white area around the rack is preserved much better by the Fancy PCA in comparison.

<p align="center">
<img src="/img/fancy_pca/other_pca.png" width="400" align="middle">
</p>

###### This image helps highlight the challenge of this task for the NN. It's unclear if the class is supposed to be the towel or the shelf/wrack that it is hanging from. Note that for most of the Fancy PCA the colors are stable but shifted. In comparison the 3rd column again has the rainbow Instragram filter effect again.

> The second form of data augmentation consists of altering the intensities of the RGB channels in
> training images. Specifically, we perform PCA on the set of RGB pixel values throughout the
> ImageNet training set. To each training image, we add multiples of the found principal components,
> with magnitudes proportional to the corresponding eigenvalues times a random variable drawn from
> a Gaussian with mean zero and standard deviation 0.1. 

> Therefore to each RGB image pixel 
<p align="center">
<img src="/img/fancy_pca/fancy_pca_formula_1.png" width="400" align="middle">
</p>

 > we add the following quantity:
 
<p align="center">
<img src="/img/fancy_pca/fancy_pca_formula_2.png" width="600" align="middle">
</p>

> where pi and λi are ith eigenvector and eigenvalue of the 3 × 3 covariance matrix of RGB pixel
> values, respectively, and αi is the aforementioned random variable. Each αi is drawn only once
> for all the pixels of a particular training image until that image is used for training again, at which
> point it is re-drawn. This scheme approximately captures an important property of natural images,
> namely, that object identity is invariant to changes in the intensity and color of the illumination. This
> scheme reduces the top-1 error rate by over 1%.

